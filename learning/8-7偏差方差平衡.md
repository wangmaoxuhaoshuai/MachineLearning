#偏差方差权衡
>Bias Variance Trade Off

##模型误差
模型误差 = 偏差（Bias）+ 方差（Variance）+ 不可避免的误差

##偏差（Bias）
###导致偏差的主要原因：

对问题本身的假设不正确！
如：非线性数据使用线性回归<br>欠拟合underfitting

##方差（Variance）
数据的一点点扰动都会较大地影响模型。通常原因，使用得模型太复杂，如高阶多项式回归
 <br>过拟合overfitting

##偏差和方差
有一些算法天生时高方差得算法 kNN
<br>非参数学习通常都是高方差算法，因为不对数据进行任何假设
<br>有一些算法天生是高偏差算法 线性回归
<br>参数学习通常都是高偏差算法，因为对数据具有极强的假设
<br>大多数算法具有相应的参数，可以调整偏差和方差，如kNN中的k，如线性回归中使用多项式回归
<br>偏差和方差通常是矛盾的，降低偏差，会提高方差，降低方差会提高偏差

##方差
在算法的方面，机器学习的主要挑战来自于方差！
<br>解决高方差，即解决过拟合
1.  降低模型复杂度
2.  减少数据维度
3.  增加样本数
4.  使用验证集
5.  模型正则化